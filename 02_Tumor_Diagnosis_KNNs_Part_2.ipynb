{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Tumor Diagnosis_KNNs_Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY9gGb3WYsHGVZRqHcNSwf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohd-faizy/07P_Exploratory_Data_Analysis_With_Seaborn/blob/master/02_Tumor_Diagnosis_KNNs_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPgWl8-Anvz1",
        "colab_type": "text"
      },
      "source": [
        "# __Tumor Diagnosis: Part-2 Machine Learning & Data Preprocessing Using KNN Algorithm__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vveaxlODuqf",
        "colab_type": "text"
      },
      "source": [
        "## __Task 1: Loading Libraries and Data__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y34Beko2D52O",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c8dca46e-ed2b-4c38-d06e-9abe46f198a0"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fb5d0d17-9ed9-46b7-be6f-5f32952a2818\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fb5d0d17-9ed9-46b7-be6f-5f32952a2818\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving breast_cancer_data.csv to breast_cancer_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZnsSfPiDuqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "19106dd2-1970-492d-df42-c87f69048e6f"
      },
      "source": [
        "import matplotlib.pyplot as plt     # For general visualizations\n",
        "import seaborn as sns               # Much better visualizations\n",
        "import numpy as np                  # For mathematical operations\n",
        "import pandas as pd                 # For working with .csv file\n",
        "import time                         # Python time library\n",
        "\n",
        "#keep every visualization inside the browser window\n",
        "%matplotlib inline "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTJSS9lDDuqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('/content/breast_cancer_data.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez0zQfnl69Lo",
        "colab_type": "text"
      },
      "source": [
        "## __Task 2: Data Preprocessing &  Normalization__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvyr1JpBoyJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a96d5336-7be1-440d-f952-993ec4528cf2"
      },
      "source": [
        "# importing data again as it will keep preprocessing stage clean --> start\n",
        "dataset = pd.read_csv('/content/breast_cancer_data.csv')\n",
        "\n",
        "# Setting diagnosis column as our target varible\n",
        "y_target = dataset.diagnosis\n",
        "\n",
        "# Counting the 'B' & 'M'\n",
        "y_target.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErL91rpgTyJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changing the target values from string to binary numbers\n",
        "\n",
        "'''\n",
        "when the target values == 'M' --True --  its change target value to binary 0\n",
        "& when the target value is false i.e. 'B' it changes it to binary 1\n",
        "'''\n",
        "y_target = np.where(y_target.values == 'M', 0, 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AHgCOGyON4m",
        "colab_type": "text"
      },
      "source": [
        "> __Mapping the values in the pandas datafram__\n",
        "\n",
        "```\n",
        "dataset['diagnosis'] = dataset['diagnosis'].map({'M': 0,'B': 1})\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eqFVAUCT4Yx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "f1d0a2c1-f979-4abd-eb2d-7f8477a3546b"
      },
      "source": [
        "dataset.head(-10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.990</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.300100</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.053730</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.71190</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.570</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.086900</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.018600</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.24160</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.690</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.197400</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.038320</td>\n",
              "      <td>0.020580</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.45040</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.420</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.241400</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.056610</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.68690</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.290</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.198000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.056880</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.40000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>924632</td>\n",
              "      <td>B</td>\n",
              "      <td>12.880</td>\n",
              "      <td>28.92</td>\n",
              "      <td>82.50</td>\n",
              "      <td>514.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.05824</td>\n",
              "      <td>0.061950</td>\n",
              "      <td>0.02343</td>\n",
              "      <td>0.1566</td>\n",
              "      <td>0.05708</td>\n",
              "      <td>0.2116</td>\n",
              "      <td>1.3600</td>\n",
              "      <td>1.502</td>\n",
              "      <td>16.83</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>0.02153</td>\n",
              "      <td>0.038980</td>\n",
              "      <td>0.007620</td>\n",
              "      <td>0.01695</td>\n",
              "      <td>0.002801</td>\n",
              "      <td>13.89</td>\n",
              "      <td>35.74</td>\n",
              "      <td>88.84</td>\n",
              "      <td>595.7</td>\n",
              "      <td>0.1227</td>\n",
              "      <td>0.16200</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.06493</td>\n",
              "      <td>0.2372</td>\n",
              "      <td>0.07242</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>924934</td>\n",
              "      <td>B</td>\n",
              "      <td>10.290</td>\n",
              "      <td>27.61</td>\n",
              "      <td>65.67</td>\n",
              "      <td>321.4</td>\n",
              "      <td>0.09030</td>\n",
              "      <td>0.07658</td>\n",
              "      <td>0.059990</td>\n",
              "      <td>0.02738</td>\n",
              "      <td>0.1593</td>\n",
              "      <td>0.06127</td>\n",
              "      <td>0.2199</td>\n",
              "      <td>2.2390</td>\n",
              "      <td>1.437</td>\n",
              "      <td>14.46</td>\n",
              "      <td>0.012050</td>\n",
              "      <td>0.02736</td>\n",
              "      <td>0.048040</td>\n",
              "      <td>0.017210</td>\n",
              "      <td>0.01843</td>\n",
              "      <td>0.004938</td>\n",
              "      <td>10.84</td>\n",
              "      <td>34.91</td>\n",
              "      <td>69.57</td>\n",
              "      <td>357.6</td>\n",
              "      <td>0.1384</td>\n",
              "      <td>0.17100</td>\n",
              "      <td>0.20000</td>\n",
              "      <td>0.09127</td>\n",
              "      <td>0.2226</td>\n",
              "      <td>0.08283</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>924964</td>\n",
              "      <td>B</td>\n",
              "      <td>10.160</td>\n",
              "      <td>19.59</td>\n",
              "      <td>64.73</td>\n",
              "      <td>311.7</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.07504</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.01116</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.06331</td>\n",
              "      <td>0.2441</td>\n",
              "      <td>2.0900</td>\n",
              "      <td>1.648</td>\n",
              "      <td>16.80</td>\n",
              "      <td>0.012910</td>\n",
              "      <td>0.02222</td>\n",
              "      <td>0.004174</td>\n",
              "      <td>0.007082</td>\n",
              "      <td>0.02572</td>\n",
              "      <td>0.002278</td>\n",
              "      <td>10.65</td>\n",
              "      <td>22.88</td>\n",
              "      <td>67.88</td>\n",
              "      <td>347.3</td>\n",
              "      <td>0.1265</td>\n",
              "      <td>0.12000</td>\n",
              "      <td>0.01005</td>\n",
              "      <td>0.02232</td>\n",
              "      <td>0.2262</td>\n",
              "      <td>0.06742</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>925236</td>\n",
              "      <td>B</td>\n",
              "      <td>9.423</td>\n",
              "      <td>27.88</td>\n",
              "      <td>59.26</td>\n",
              "      <td>271.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.04971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1742</td>\n",
              "      <td>0.06059</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>2.9270</td>\n",
              "      <td>3.618</td>\n",
              "      <td>29.11</td>\n",
              "      <td>0.011590</td>\n",
              "      <td>0.01124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.03004</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>10.49</td>\n",
              "      <td>34.24</td>\n",
              "      <td>66.50</td>\n",
              "      <td>330.6</td>\n",
              "      <td>0.1073</td>\n",
              "      <td>0.07158</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.2475</td>\n",
              "      <td>0.06969</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>925277</td>\n",
              "      <td>B</td>\n",
              "      <td>14.590</td>\n",
              "      <td>22.68</td>\n",
              "      <td>96.39</td>\n",
              "      <td>657.1</td>\n",
              "      <td>0.08473</td>\n",
              "      <td>0.13300</td>\n",
              "      <td>0.102900</td>\n",
              "      <td>0.03736</td>\n",
              "      <td>0.1454</td>\n",
              "      <td>0.06147</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>1.1080</td>\n",
              "      <td>2.224</td>\n",
              "      <td>19.54</td>\n",
              "      <td>0.004242</td>\n",
              "      <td>0.04639</td>\n",
              "      <td>0.065780</td>\n",
              "      <td>0.016060</td>\n",
              "      <td>0.01638</td>\n",
              "      <td>0.004406</td>\n",
              "      <td>15.48</td>\n",
              "      <td>27.27</td>\n",
              "      <td>105.90</td>\n",
              "      <td>733.5</td>\n",
              "      <td>0.1026</td>\n",
              "      <td>0.31710</td>\n",
              "      <td>0.36620</td>\n",
              "      <td>0.11050</td>\n",
              "      <td>0.2258</td>\n",
              "      <td>0.08004</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>559 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "554    924632         B  ...                  0.07242          NaN\n",
              "555    924934         B  ...                  0.08283          NaN\n",
              "556    924964         B  ...                  0.06742          NaN\n",
              "557    925236         B  ...                  0.06969          NaN\n",
              "558    925277         B  ...                  0.08004          NaN\n",
              "\n",
              "[559 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWHGMy3IT-Da",
        "colab_type": "text"
      },
      "source": [
        "> `id, diagnosis and unnamed: 32` are not necessary for training the data. So let's drop these column. \n",
        "\n",
        "$'diagnosis'$ is a target varible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmLkz5deT8mM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37887c0e-c99f-48f3-ab55-dec010a931a9"
      },
      "source": [
        "list = ['Unnamed: 32', 'id', 'diagnosis']\n",
        "data = dataset.drop(list,axis = 1)\n",
        "data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xGAhRDSYvwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "fc9a69b2-5564-4a66-8dd5-6d8371a501b3"
      },
      "source": [
        "data.head(-10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.990</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.300100</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.053730</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.71190</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.570</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.086900</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.018600</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.24160</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.690</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.197400</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.038320</td>\n",
              "      <td>0.020580</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.45040</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.420</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.241400</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.056610</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.68690</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.290</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.198000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.056880</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.40000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>12.880</td>\n",
              "      <td>28.92</td>\n",
              "      <td>82.50</td>\n",
              "      <td>514.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.05824</td>\n",
              "      <td>0.061950</td>\n",
              "      <td>0.02343</td>\n",
              "      <td>0.1566</td>\n",
              "      <td>0.05708</td>\n",
              "      <td>0.2116</td>\n",
              "      <td>1.3600</td>\n",
              "      <td>1.502</td>\n",
              "      <td>16.83</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>0.02153</td>\n",
              "      <td>0.038980</td>\n",
              "      <td>0.007620</td>\n",
              "      <td>0.01695</td>\n",
              "      <td>0.002801</td>\n",
              "      <td>13.89</td>\n",
              "      <td>35.74</td>\n",
              "      <td>88.84</td>\n",
              "      <td>595.7</td>\n",
              "      <td>0.1227</td>\n",
              "      <td>0.16200</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.06493</td>\n",
              "      <td>0.2372</td>\n",
              "      <td>0.07242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>10.290</td>\n",
              "      <td>27.61</td>\n",
              "      <td>65.67</td>\n",
              "      <td>321.4</td>\n",
              "      <td>0.09030</td>\n",
              "      <td>0.07658</td>\n",
              "      <td>0.059990</td>\n",
              "      <td>0.02738</td>\n",
              "      <td>0.1593</td>\n",
              "      <td>0.06127</td>\n",
              "      <td>0.2199</td>\n",
              "      <td>2.2390</td>\n",
              "      <td>1.437</td>\n",
              "      <td>14.46</td>\n",
              "      <td>0.012050</td>\n",
              "      <td>0.02736</td>\n",
              "      <td>0.048040</td>\n",
              "      <td>0.017210</td>\n",
              "      <td>0.01843</td>\n",
              "      <td>0.004938</td>\n",
              "      <td>10.84</td>\n",
              "      <td>34.91</td>\n",
              "      <td>69.57</td>\n",
              "      <td>357.6</td>\n",
              "      <td>0.1384</td>\n",
              "      <td>0.17100</td>\n",
              "      <td>0.20000</td>\n",
              "      <td>0.09127</td>\n",
              "      <td>0.2226</td>\n",
              "      <td>0.08283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>10.160</td>\n",
              "      <td>19.59</td>\n",
              "      <td>64.73</td>\n",
              "      <td>311.7</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.07504</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.01116</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.06331</td>\n",
              "      <td>0.2441</td>\n",
              "      <td>2.0900</td>\n",
              "      <td>1.648</td>\n",
              "      <td>16.80</td>\n",
              "      <td>0.012910</td>\n",
              "      <td>0.02222</td>\n",
              "      <td>0.004174</td>\n",
              "      <td>0.007082</td>\n",
              "      <td>0.02572</td>\n",
              "      <td>0.002278</td>\n",
              "      <td>10.65</td>\n",
              "      <td>22.88</td>\n",
              "      <td>67.88</td>\n",
              "      <td>347.3</td>\n",
              "      <td>0.1265</td>\n",
              "      <td>0.12000</td>\n",
              "      <td>0.01005</td>\n",
              "      <td>0.02232</td>\n",
              "      <td>0.2262</td>\n",
              "      <td>0.06742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>9.423</td>\n",
              "      <td>27.88</td>\n",
              "      <td>59.26</td>\n",
              "      <td>271.3</td>\n",
              "      <td>0.08123</td>\n",
              "      <td>0.04971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1742</td>\n",
              "      <td>0.06059</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>2.9270</td>\n",
              "      <td>3.618</td>\n",
              "      <td>29.11</td>\n",
              "      <td>0.011590</td>\n",
              "      <td>0.01124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.03004</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>10.49</td>\n",
              "      <td>34.24</td>\n",
              "      <td>66.50</td>\n",
              "      <td>330.6</td>\n",
              "      <td>0.1073</td>\n",
              "      <td>0.07158</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.2475</td>\n",
              "      <td>0.06969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>14.590</td>\n",
              "      <td>22.68</td>\n",
              "      <td>96.39</td>\n",
              "      <td>657.1</td>\n",
              "      <td>0.08473</td>\n",
              "      <td>0.13300</td>\n",
              "      <td>0.102900</td>\n",
              "      <td>0.03736</td>\n",
              "      <td>0.1454</td>\n",
              "      <td>0.06147</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>1.1080</td>\n",
              "      <td>2.224</td>\n",
              "      <td>19.54</td>\n",
              "      <td>0.004242</td>\n",
              "      <td>0.04639</td>\n",
              "      <td>0.065780</td>\n",
              "      <td>0.016060</td>\n",
              "      <td>0.01638</td>\n",
              "      <td>0.004406</td>\n",
              "      <td>15.48</td>\n",
              "      <td>27.27</td>\n",
              "      <td>105.90</td>\n",
              "      <td>733.5</td>\n",
              "      <td>0.1026</td>\n",
              "      <td>0.31710</td>\n",
              "      <td>0.36620</td>\n",
              "      <td>0.11050</td>\n",
              "      <td>0.2258</td>\n",
              "      <td>0.08004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>559 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0         17.990         10.38  ...          0.4601                  0.11890\n",
              "1         20.570         17.77  ...          0.2750                  0.08902\n",
              "2         19.690         21.25  ...          0.3613                  0.08758\n",
              "3         11.420         20.38  ...          0.6638                  0.17300\n",
              "4         20.290         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "554       12.880         28.92  ...          0.2372                  0.07242\n",
              "555       10.290         27.61  ...          0.2226                  0.08283\n",
              "556       10.160         19.59  ...          0.2262                  0.06742\n",
              "557        9.423         27.88  ...          0.2475                  0.06969\n",
              "558       14.590         22.68  ...          0.2258                  0.08004\n",
              "\n",
              "[559 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts7KZKv_6shi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "887unejnBX-8",
        "colab_type": "text"
      },
      "source": [
        "[__Difference between Standard scaler and MinMaxScaler?__](https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY7d1kbT8spg",
        "colab_type": "text"
      },
      "source": [
        "__Minmax scaler formula__\n",
        "\n",
        "> MinMaxScaler rescales the data set such that all feature values are in the range [0, 1] \n",
        "\n",
        "$X_{new} = \\frac{X_i - min(X)}{max(X) - min(X)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BU6AJpb72G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()  # Data normalization"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q31rGkt732Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "97aff413-e8c3-4725-e0c8-47277414e409"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Y21MS1CP9u",
        "colab_type": "text"
      },
      "source": [
        "> $Not-Normalized$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuXKf-Nb8dxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "ee467079-5434-435b-b232-9cabf72f8dd0"
      },
      "source": [
        "# fit is to train any model in sklearn library\n",
        "# and transform is to scale the data\n",
        "data = scaler.fit_transform(data) \n",
        "data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
              "        0.41886396],\n",
              "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
              "        0.22287813],\n",
              "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
              "        0.21343303],\n",
              "       ...,\n",
              "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
              "        0.1519087 ],\n",
              "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
              "        0.45231536],\n",
              "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
              "        0.10068215]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkUrmpxLCjwN",
        "colab_type": "text"
      },
      "source": [
        "> __Normalized__: as the gap between data is much smaller now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEi6HFUTEoYU",
        "colab_type": "text"
      },
      "source": [
        "## __Task 3: Spliting the data into test and traning dataset__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yijo9bukQOzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6a_mr4OQTKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, y_target, test_size = 0.1)\n",
        "# X is features, target is y\n",
        "# test_set = 10% of our data set size"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGh_dRPcQw53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "da43c43d-b77a-4fe8-bd40-c682c84e91c6"
      },
      "source": [
        "print(data.shape)\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30)\n",
            "(57, 30)\n",
            "(512, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCingbPYbhoF",
        "colab_type": "text"
      },
      "source": [
        "## __Task 4: K-Nearest Neighbors Algorithm(KNNs)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORlEw6Vgb-oJ",
        "colab_type": "text"
      },
      "source": [
        "> - [__Introduction to k-Nearest Neighbors --> analyticsvidhya.com__](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)\n",
        "- [__KNN Algorithm - Finding Nearest Neighbors --> tutorialspoint.com__](https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_knn_algorithm_finding_nearest_neighbors.htm) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VDkqGIhd-O2",
        "colab_type": "text"
      },
      "source": [
        "### __KNN__\n",
        "- __Supervised ML algorithm__\n",
        "- Can be used for both __Classification__ as well as __Regression__.\n",
        "\n",
        "> __K-nearest neighbors (KNN)__ algorithm uses _‘feature similarity’_ to predict the values of new datapoints which further means that the new data point will be assigned a value based on how closely it matches the points in the training set.\n",
        "\n",
        "$Steps:$\n",
        "\n",
        "- $Step-1$: Load the training as well as test data.\n",
        "- $Step-2$: Choose the value of $K$ i.e. the nearest data points. $K$ can be any integer.\n",
        "- $Step-3$:  For each point in the test data do the following:\n",
        "    - Calculate the distance between test data and each row of training data with the help of any of the method namely: Euclidean, Manhattan or Hamming distance. The most commonly used method to calculate distance is __Euclidean__.\n",
        "    - Now, based on the distance value, sort them in __Ascending order__.\n",
        "    - Next, it will choose the top $K$ rows from the sorted array.\n",
        "    - Now, it will assign a class to the test point based on most frequent class of these rows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1anFiSX9ox61",
        "colab_type": "text"
      },
      "source": [
        "__Eucledian distance__\n",
        "![__Eucledian distance__](https://upload.wikimedia.org/wikipedia/commons/1/10/Euclidean_distance_3d_2_cropped.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4XvQlciv7U",
        "colab_type": "text"
      },
      "source": [
        "__Example__\n",
        "\n",
        "Suppose we have a dataset which can be plotted as follows −\n",
        "![KNN1](https://www.tutorialspoint.com/machine_learning_with_python/images/concept_of_k.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvqiKP-UmVvp",
        "colab_type": "text"
      },
      "source": [
        "Now, we need to classify new data point with black dot (at point 60,60) into blue or red class. We are assuming K = 3 i.e. it would find three nearest data points. It is shown in the next diagram −\n",
        "\n",
        "![KNN-2](https://www.tutorialspoint.com/machine_learning_with_python/images/knn_algorithm.jpg)\n",
        "\n",
        "We can see in the above diagram the three nearest neighbors of the data point with black dot. Among those three, two of them lies in Red class hence the black dot will also be assigned in red class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7JhKzCbm7Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the KNN from the Sklearn library\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZAG-TsQmVNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4STwowCPkkL9",
        "colab_type": "text"
      },
      "source": [
        "### __Grid Search & hyperparameter__\n",
        "\n",
        "This technique is used to find the _Optimal parameters_ to use with an algorithm. This is NOT the weights or the model, those are learned using the data.\n",
        "\n",
        "__Hyper-parameters__ are like the $k$ in __k-Nearest Neighbors (KNNs)__. $KNNs$ requires the user to select which neighbor to consider when calculating the distance. The algorithm then tunes a parameter, a threshold, to see if a novel example falls within the learned distribution, this is done with the data.\n",
        "\n",
        "> __This method will be able to best determine which k is the optimal to use for your data.__\n",
        "\n",
        "__How does it work?__\n",
        "\n",
        "First we build a grid. This is essentially a set of possible values that hyper-parameter can take. For our case we can use `[3, 5, 7, 11, 15]`. Then you will train your $KNN$ model for _each value_ in the grid. \n",
        "\n",
        "First we would do 3-NN, then 5-NN, and so on. For each iteration we will get a performance score which will tell you how well your algorithm performed using that value for the hyper-parameter. After we have gone through the entire grid we will select the value that gave the best performance.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLc4_QtDnsjb",
        "colab_type": "text"
      },
      "source": [
        "[Nearest Neighbor Algorithms¶](https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/neighbors.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Au5v8gZ5rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating parameter grid\n",
        "param_grid = {'n_neighbors': [5, 7, 11, 15],\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "              'leaf_size': [10, 30, 50, 100]}\n",
        "\n",
        "grid_search = GridSearchCV(knn, param_grid = param_grid)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymcE-rK9qww1",
        "colab_type": "text"
      },
      "source": [
        "$Syntax$\n",
        "\n",
        "```\n",
        "KNeighborsClassifier(n_neighbors=5,\n",
        "                     weights=’uniform’,\n",
        "                     algorithm=’auto’,\n",
        "                     leaf_size=30,\n",
        "                     metric=’minkowski’,\n",
        "                     p=2,\n",
        "                     metric_params=None)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb-ubj6Oqlq6",
        "colab_type": "text"
      },
      "source": [
        "- `n_neighbors` are the number of neighbors that will vote for the class of the target point; default number is 5. An odd number is preferred to avoid any tie.\n",
        "\n",
        "\n",
        "- `weights` parameter has two choices: `uniform` and `distance`. For the `uniform` weight, each of the __k-neighbors__ has equal vote whatever its distance from the target point. If the weight is ‘distance‘ then voting weightage or importance varies by inverse of distance; those points who are nearest to the target point have greater influence than those who are farther away.\n",
        "\n",
        "- Parameter `algorithm` is for selecting the indexing data structure that will be used for speeding up neighborhood search; value of `auto` leaves it to algorithm to make the best choice among the three.the three algorithms, `brute`, `kd_tree`and `ball_tree`.\n",
        "\n",
        "> [__A working example of K-d tree formation and K-Nearest Neighbor algorithms__](https://ashokharnal.wordpress.com/2015/01/20/a-working-example-of-k-d-tree-formation-and-k-nearest-neighbor-algorithms/)\n",
        "\n",
        "- `leaf_size`:  Parameter ‘leaf_size‘ is the size of leaf in `kd_tree` or `ball_tree`. __Larger the size, greater the speed of initial indexing structure formation__ but at the cost of __delay in classification of target point__.\n",
        "\n",
        "\n",
        "- Parameter `metric` decides how distances are calculated in space. One familiar way is __euclidean distance__ but then in some cases other measures of distances such as __Manhattan distance__ are also used. A general formulation of distance metric is `minkowski` distance. When parameter $p$ is 2, it is the same as __Euclidean distance__ and when parameter $p$ is 1, it is __Manhattan distance__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg_YZLx7pmWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "2fb4194d-69d1-46b2-f018-543e63936d79"
      },
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                            metric='minkowski',\n",
              "                                            metric_params=None, n_jobs=None,\n",
              "                                            n_neighbors=5, p=2,\n",
              "                                            weights='uniform'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
              "                         'leaf_size': [10, 30, 50, 100],\n",
              "                         'n_neighbors': [5, 7, 11, 15]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxhuUS394GeV",
        "colab_type": "text"
      },
      "source": [
        "> __Getting the best set of parameters from grid search__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHkXB2b84D-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "418282a1-9828-43e3-b469-277dc13f5b2f"
      },
      "source": [
        "grid_search.best_estimator_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqYbWRu04Woa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using the best set of parameter from the grid search\n",
        "knn = KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
        "                     weights='uniform')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDJzoymz4xgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "27b74051-f793-481d-b189-9eb8fc10e2a5"
      },
      "source": [
        "# fitting the knn parameters\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYqpSzBXLtOb",
        "colab_type": "text"
      },
      "source": [
        "##  __Task 5: Model Evaluation__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6cASyYPLdkc",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://interviewbubble.com/wp-content/uploads/2019/03/1pOtBHai4jFd-ujaNXPilRg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DFILu8MAXEC",
        "colab_type": "text"
      },
      "source": [
        "### __Accuracy__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8almmEJ645dJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeDUardxAu9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = knn.predict(X_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g2cbH5nAxx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fa36eac-85e4-4fbf-b1a4-e4c5263ef35a"
      },
      "source": [
        "print(\"Accuracy: {}%\".format(accuracy_score(y_test,predict)*100))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 96.49122807017544%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4nP7JEcA3qp",
        "colab_type": "text"
      },
      "source": [
        "### __Confusion matrix__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GAWKT8tBEse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQTWaP3cBIHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix= confusion_matrix(y_test, predict)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkjFoxH0BJsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "3108bd1e-2f53-49ab-980e-21d030dbf033"
      },
      "source": [
        "sns.heatmap(matrix,annot = True, fmt = \"d\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbbc0590160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nCtkssXBV_b",
        "colab_type": "text"
      },
      "source": [
        "### __Precision score__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWs7W8F4Bc8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee8_IgInBee7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision = precision_score(y_test, predict)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFiveXDVBgA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f11484f4-c5d7-4b95-e500-19a1edf4fb3e"
      },
      "source": [
        "print(\"Precision: \", precision)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:  0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfxlOtVOFL3u",
        "colab_type": "text"
      },
      "source": [
        "### __Recall__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyvOZ1hcLMq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzM4vwDOLQDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recall = recall_score(y_test, predict)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF4vtv-BLR4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "641c6bde-777f-4abd-e32b-3c60825a244f"
      },
      "source": [
        "print(\"Recall: \", recall)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall:  0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}